<?xml version="1.0" encoding="UTF-8" ?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"> <channel><title>Liam Connell&#39;s Blog</title><description>I write about ML and software engineering</description><link>https://liamconnell.github.io/</link><atom:link href="https://liamconnell.github.io/feed_rss_created.xml" rel="self" type="application/rss+xml" /><language>en</language> <pubDate>Fri, 23 Jan 2026 16:26:14 -0000</pubDate> <lastBuildDate>Fri, 23 Jan 2026 16:26:14 -0000</lastBuildDate> <ttl>1440</ttl> <generator>MkDocs RSS plugin - v1.17.3</generator> <image> <url>None</url> <title>Liam Connell's Blog</title><link>https://liamconnell.github.io/</link> </image> <item> <title>What does it feel like to be an agent?</title> <description>&lt;h1&gt;What does it feel like to be an agent?&lt;/h1&gt;&lt;h2&gt;Why this question will change how you design agents&lt;/h2&gt;&lt;p&gt;What does it feel like to be an AI agent? This question, often the cast aside as the domain of armchair AI philosophers, in fact has highly practical implications for how we design the AI agents that will transform&lt;/p&gt;</description><link>https://liamconnell.github.io/blog/2026/01/23/what-does-it-feel-like-to-be-an-agent/</link> <pubDate>Fri, 23 Jan 2026 00:00:00 +0000</pubDate><source url="https://liamconnell.github.io/feed_rss_created.xml">Liam Connell's Blog</source><guid isPermaLink="true">https://liamconnell.github.io/blog/2026/01/23/what-does-it-feel-like-to-be-an-agent/</guid> </item> <item> <title>Tiki-Taka Reinforcement Learning</title> <description>&lt;h1&gt;Tiki-Taka Reinforcement Learning&lt;/h1&gt;&lt;video controls src=&#34;/assets/videos/game_update_04999.mp4&#34; title=&#34;Title&#34;&gt;&lt;/video&gt;&lt;p&gt;I asked my colleagues if anyone else misses the days before foundation model AI. That simpler time between 2015 and 2022 when the field of artificial intelligence was showing enough early commercial promise to keep us gainfully employed, but was so layered with math and statistics that it kept out the vast majority of software engineers. It felt like a secret society for those who had happened to pay attention in undergraduate linear algebra and probability classes.&lt;/p&gt;</description><link>https://liamconnell.github.io/blog/2026/01/18/tiki-taka-reinforcement-learning/</link> <pubDate>Sun, 18 Jan 2026 00:00:00 +0000</pubDate><source url="https://liamconnell.github.io/feed_rss_created.xml">Liam Connell's Blog</source><guid isPermaLink="true">https://liamconnell.github.io/blog/2026/01/18/tiki-taka-reinforcement-learning/</guid> </item> <item> <title>5 Archetypes of Knowledge-Intensive Applications</title> <description>&lt;h1&gt;5 Archetypes of Knowledge-Intensive Applications&lt;/h1&gt;&lt;h3&gt;It doesn&#39;t always have to be RAG.&lt;/h3&gt;&lt;p&gt;The current GenAI boom has seen the rise of the Retrieval Augmented Generation (RAG) architecture, which promises to enhance the functionality of chatbots by providing them with context from a knowledge base. In some circles, RAG has become synonymous with LLM-based applications. &lt;/p&gt;&lt;p&gt;I think this is a mistake, and I believe that many of the most valuable use cases that leverage LLM technology will do so without anything that resembles RAG. &lt;/p&gt;</description><link>https://liamconnell.github.io/blog/2024/06/12/5-archetypes-of-knowledge-intensive-applications/</link> <pubDate>Wed, 12 Jun 2024 00:00:00 +0000</pubDate><source url="https://liamconnell.github.io/feed_rss_created.xml">Liam Connell's Blog</source><guid isPermaLink="true">https://liamconnell.github.io/blog/2024/06/12/5-archetypes-of-knowledge-intensive-applications/</guid> </item> <item> <title>A tour through tensorflow with financial data</title> <description>&lt;h1&gt;A tour through tensorflow with financial data&lt;/h1&gt;&lt;p&gt;I present several models ranging in complexity from simple regression to LSTM and policy networks. The series can be used as an educational resource for tensorflow or deep learning, a reference aid, or a source of ideas on how to apply deep learning techniques to problems that are outside of the usual deep learning fields (vision, natural language).&lt;/p&gt;</description><link>https://liamconnell.github.io/blog/2016/07/18/a-tour-through-tensorflow-with-financial-data/</link> <pubDate>Mon, 18 Jul 2016 00:00:00 +0000</pubDate><source url="https://liamconnell.github.io/feed_rss_created.xml">Liam Connell's Blog</source><guid isPermaLink="true">https://liamconnell.github.io/blog/2016/07/18/a-tour-through-tensorflow-with-financial-data/</guid> </item> <item> <title>Deep Learning Reading List</title> <description>&lt;h1&gt;Deep Learning Reading List&lt;/h1&gt;&lt;p&gt;There is a lot written online about deep learning and AI. Ignoring the fluff and product-hype articles, you’re left with a huge resource for learning the technical side of the field. I won’t claim to have read everything out there, but here are some of the most useful things that I have found. The purpose of this list is not to be a definitive curriculum, but to recommend some of the high-quality educational material that’s out there. If there is an article that you think belongs on this list send me an &lt;a href=&#34;ljrconnell@gmail.com&#34;&gt;email&lt;/a&gt;. &lt;/p&gt;</description><link>https://liamconnell.github.io/blog/2016/07/08/deep-learning-reading-list/</link> <pubDate>Fri, 08 Jul 2016 00:00:00 +0000</pubDate><source url="https://liamconnell.github.io/feed_rss_created.xml">Liam Connell's Blog</source><guid isPermaLink="true">https://liamconnell.github.io/blog/2016/07/08/deep-learning-reading-list/</guid> </item> </channel></rss>